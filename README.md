# ğŸ¬ MovieQA-GPT-Bot ğŸ¤

> AI-powered Question Answering Bot over Movie Transcripts using RAG (Retrieval-Augmented Generation)

MovieQA-GPT-Bot is a production-ready, Dockerized AI system that lets users ask natural language questions about movie plots or scenes. It uses vector databases and Large Language Models (LLMs) to answer contextually using actual **movie transcripts**.

---

## ğŸ” Key Features

- ğŸï¸ Ingests and indexes full movie transcripts
- ğŸ§  Uses **RAG (Retrieval-Augmented Generation)** pipeline with OpenAI/GPT models
- ğŸ” Semantic search using `ChromaDB` + `FAISS`
- ğŸ³ Fully Dockerized with `Dockerfile` and `docker-compose.yaml`
- ğŸ§ª Modular design â€” easy to plug in new LLMs or datasets

---
## ğŸ§° Tech Stack

| Component              | Technology / Library                   |
|------------------------|----------------------------------------|
| Language & Runtime     | PythonÂ 3.10+                           |
| UI                     | Streamlit *(or React + Tailwind)*     |
| Orchestrator / Agent   | LangChain *(Agents & Chains)*         |
| Transcript Loader      | `youtube_transcript_api`              |
| Chunking & Embedding   | HuggingFace `all-MiniLM-L6-v2`        |
| Vector DB              | Chroma DB                             |

---
## ğŸ“ Project Structure

```
movieqa_bot/
â”œâ”€â”€ app.py # Entry point for the bot
â”œâ”€â”€ Dockerfile # Docker setup
â”œâ”€â”€ docker-compose.yaml # Multi-container orchestration
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ chroma_db/ # Chroma vector DB files
â”œâ”€â”€ transcript/ # Raw movie transcript files
â”œâ”€â”€ vectorstore/ # Persisted FAISS index
â”œâ”€â”€ rag/ # RAG pipeline implementation
â”œâ”€â”€ docker/ # Docker-specific configs/scripts
â””â”€â”€ README.md # This file
```

---

## âš™ï¸ Setup & Installation

### ğŸ§  Prerequisites
- Python 3.8+
- Docker & Docker Compose

### ğŸ”§ Local Setup (Without Docker)

```bash
git clone https://github.com/<your-username>/MovieQA-GPT-Bot.git
cd MovieQA-GPT-Bot
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run app
python app.py
```

### ğŸ³ Docker-Based Setup (Recommended)
#### Build and run using Docker Compose
```
1. docker compose build
	ONLY Once, at project start or if changes in requirements.txt or Dockerfile
2.docker compose run --rm app python app.py <YOUTUBE_VIDEO_ID>
	Every code/test cycle. Instant, no rebuild.
3. (Optional) export VIDEO_ID=<YOUTUBE_VIDEO_ID> and then docker compose up
	If you want your service running continuously (e.g. with a web UI).
4. docker compose down
```
---
ğŸ§  How It Works
1. Parses and indexes movie transcripts into a Chroma vector store.
2. User asks a question â€” e.g., "What does Neo realize at the end of The Matrix?"
3. Relevant transcript chunks are retrieved via vector similarity.
4. These chunks + the user query are passed to the LLM (GPT) to generate the answer.
Answer is returned to the user via CLI or API.

---
ğŸ§ª Example Queries

Q: What is the name of the ship Morpheus commands?
A: The Nebuchadnezzar.

Q: What choice does Neo make at the end?
A: Neo chooses to sacrifice himself to save others, realizing his purpose.

---
ğŸ”® Future Enhancements

Gradio/Streamlit UI for web-based interface
Hugging Face Space deployment
Add support for multi-language transcripts
Summarization & scene-level search

---
ğŸ¤ Contributing

Pull requests are welcome. Please open issues to discuss improvements or bugs.

---
ğŸ“œ License

MIT License â€“ feel free to use, fork, and modify.

ğŸ“« Contact

Made by Sandesh Mendan
Project inspired by movie nerds + LLMs âœ¨
